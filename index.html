<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Yang Li's Homepage</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
		<script src="js/jquery.min.js"></script>
		<script src="js/jquery.scrolly.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/init.js"></script>
              <script type="text/javascript">
		    function toggle_visibility(id) {
		       var e = document.getElementById(id);
		       if(e.style.display == 'block')
		          e.style.display = 'none';
		       else if(e.style.display == 'none')
		          e.style.display = 'block';
		    }
			
			function jump_to_div(id) {
		       var e = document.getElementById(id);
		       e.scrollIntoView();
		    }
			
			function close_div(id) {
		       var e = document.getElementById(id);
		       e.style.display = 'none';
		    }
			
			function close_all_abstract() {
		       close_div('kdd13_li');
			   close_div('vldb13_li');
			   close_div('tkde13_tan');
			   close_div('kdd14_sun');
			   close_div('emnlp15_li');
			   close_div('www16_li');
			   close_div('acl18_li');
			   close_div('kc');
		    }
			
		   function openwindow(url,name,iWidth,iHeight)
		    {
		     var url;                                
		     var name;                           
		     var iWidth;                          
		     var iHeight;                        
		     var iTop = (window.screen.availHeight-30-iHeight)/1.6;      
		     var iLeft = (window.screen.availWidth-10-iWidth)/2;
			window.open(url,name,'height='+iHeight+',,innerHeight='+iHeight+',width='+iWidth+',innerWidth='+iWidth+',top='+iTop+',left='+iLeft+',toolbar=no,menubar=no,scrollbars=auto,resizeable=no,location=no,status=no');
		    }
		</script>
		
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-179268110-1"></script>
		<script>
 		  window.dataLayer = window.dataLayer || [];
  		  function gtag(){dataLayer.push(arguments);}
  		  gtag('js', new Date());

  		  gtag('config', 'UA-179268110-1');
		</script>

		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
		</noscript>

		[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]
		[if lte IE 9]><link rel="stylesheet" href="css/ie/v9.css" /><![endif]

	</head>
	<body>

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="#top" onclick="close_all_abstract();">About</a></li>
					<li><a href="#education" onclick="close_all_abstract();">Education</a></li>
					<li><a href="#research" onclick="close_all_abstract();">Research</a></li>
                    <li><a href="#pubs" onclick="close_all_abstract();">Publications</a></li>
					<li><a href="#work" onclick="close_all_abstract();">Work</a></li>
					<li><a href="#contact" onclick="close_all_abstract();">Contact</a></li>
				</ul>
			</nav>

		<!-- Home -->
			<div class="wrapper style1 first">
				<article class="container" id="top">
					<div class="row">
						<div class="4u">
							<span class="image fit"><img src="images/yang.jpg" alt="" /></span>
						</div>
						<div class="8u">
							<header>
								<h1><font face="verdana">Hi. I'm <strong>Dr. Yang Li</strong></font></h1>
							</header>
                            <p style="text-align:justify">I received my Ph.D. degree from <a href="http://cs.ucsb.edu">Computer Science Department</a> at <a href="http://www.ucsb.edu">University of California, Santa Barbara</a> and I am currently a Senior Software Engineer / Tech Lead at Google Inc. My research interests are Knowledge Graph Construction, Natural Language Understanding, Recommendation Systems, Data Mining and Machine Learning.</p>
							<a href="files/CV_Yang.pdf" class="button big scrolly">Résumé</a>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://www.linkedin.com/in/yangli1989" class="button big scrolly">LinkedIn</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="#news" class="button big scrolly">What's New</a>
						</div>
					</div>
				</article>
			</div>
			
			<!-- News -->
				<div class="wrapper style3">
					<article id="news">
						<header>
							<h2>What's New</h2>
						</header>
						<div class="container">
						<iframe src='https://cdn.knightlab.com/libs/timeline3/latest/embed/index.html?source=0AgAeAzoalCvzdHpYQ3VfX1g5V2dQODNVSWJSZTlEdGc&font=BreeSerif-OpenSans&maptype=toner&lang=en&start_at_slide=36&height=600' width='96.8%' height='650' frameborder='0'></iframe>
						</div>
					</article>
				</div>
		

		<!-- Education -->
			<div class="wrapper style2">
				<article id="education">
					<header>
						<h2>Education</h2>
					</header>
					<div class="container">
						<div class="row">
							<div class="4u">
								<section class="box style1">
									<a href="http://www.ucsb.edu" class="image"><img src="images/ucsb.jpg" alt="" /></a>
									<h3><a href="http://www.ucsb.edu">UCSB</a></h3>
									<h4>Ph.D. in Computer Science</h4>
                                    <span>Sep. 2010 - Jun. 2015</span>
                                    <p>Santa Barbara, CA</p>
								</section>
							</div>
							<div class="4u">
								<section class="box style1">

									<a href="http://www.zju.edu.cn/english/" class="image small"><img src="images/zju.png" alt="" /></a>
									<h3><a href="http://www.zju.edu.cn/english/">ZJU</a></h3>
									<h4>B.E. in Computer Science</h4>
                                    <span>Sep. 2006 - Jun. 2010</span>
                                    <p>Hangzhou, China</p>
								</section>
							</div>
							<div class="4u">
								<section class="box style1">
									<a href="http://www.ucla.edu" class="image small"><img src="images/ucla.png" alt="" /></a>
									<h3><a href="http://www.ucla.edu">UCLA</a></h3>
									<h4>Visiting Student</h4>
                                    <span>Jul. 2009 - Sep. 2009</span>
                                    <p>Los Angeles, CA</p>
								</section>
							</div>
						</div>
					</div>
				</article>
			</div>

		<!-- Research -->
			<div class="wrapper style3">
				<article id="research">
					<header>
						<h2>Research Projects</h2>
					</header>
					<div class="container">
						<div class="row">
							<div class="4u">
								<section class="box style1">
									<class="image"><img src="images/ade.jpg" width="256" height="200" border="0" alt="" />
									<h4>Acronym Disambiguation for Enterprises</h4>
                                    <a style="cursor: pointer;" onclick="close_all_abstract();toggle_visibility('acl18_li');jump_to_div('acl18_li');">[Abstract]</a>
								</section>
							</div>
							<div class="4u">
								<section class="box style1">
									<class="image"><img src="images/lned.jpg" width="256" height="200" border="0" alt="" />
									<h4>Entity Disambiguation with Linkless Knowledge Bases</h4>
                                    <a style="cursor: pointer;" onclick="close_all_abstract();toggle_visibility('www16_li');jump_to_div('www16_li');">[Abstract]</a>
								</section>
							</div>
							<div class="4u">
								<section class="box style1">
									<class="image"><img src="images/mened.png" width="256" height="200" border="0" alt="" />
									<h4>Mining Evidences for Named Entity Disambiguation</h4>
                                    <a style="cursor: pointer;" onclick="close_all_abstract();toggle_visibility('kdd13_li');jump_to_div('kdd13_li');">[Abstract]</a>
								</section>
							</div>
						</div>
						<div class="row">
                            <div class="4u">
								<section class="box style1">
									<class="image"><img src="images/graphqa.png" width="256" height="200" border="0" alt="" />
									<h4>Answering Elementary Science Questions via Coherent Scenes</h4>
                                    <a style="cursor: pointer;" onclick="close_all_abstract();toggle_visibility('emnlp15_li');jump_to_div('emnlp15_li');">[Abstract]</a>
								</section>
							</div>
							<div class="4u">
								<section class="box style1">
									<class="image"><img src="images/sv.jpg" width="249" height="202" border="0" alt="" />
									<h4>Interpreting Public Sentiment Variations on Twitter</h4>
                                    <a style="cursor: pointer;" onclick="close_all_abstract();toggle_visibility('tkde13_tan');jump_to_div('tkde13_tan');">[Abstract]</a>
								</section>
							</div>
							<div class="4u">
								<section class="box style1">
									<class="image"><img src="images/msp.png" width="256" height="200" border="0" alt="" />
									<h4>Memory Efficient Minimum Substring Partitioning</h4>
                                    <a style="cursor: pointer;" onclick="close_all_abstract();toggle_visibility('vldb13_li');jump_to_div('vldb13_li');">[Abstract]</a>
								</section>
							</div>
						</div>
					</div>
					<footer>
						<a href="#pubs" class="button big scrolly">See my related publications</a>
					</footer>
				</article>
			</div>
            
            <!-- Pubs -->
			<div class="wrapper wrapper-style3">
				<article id="pubs">
					<header>
						<h2>Selected Publications</h2>
					</header>
					<div class="container">
						<div class="entry-content">
							<ul align="justify">
								<li>
								<p><br\></br\></p>
									<div>[1] Ji Yang, Xinyang Yi, Derek Zhiyuan Cheng, Lichan Hong, <strong>Yang Li</strong>, Simon Xiaoming Wang, Taibai Xu, and Ed H. Chi., "<strong>Mixed Negative Sampling for Learning Two-tower Neural Networks in Recommendations</strong>", <em>Companion Proc. of the Web Conference 2020 (<b>WWW'20</b>)</em>, Taipei, April 2020. <a style="cursor: pointer;" onclick="toggle_visibility('www20_yang');">[Abstract]</a> <a href="#pubs">[Paper]</a> <a href="#pubs">  [Citations]</a>
	                                    <div id="www20_yang" style="display: none;">
	                                    	<section class="box box-style1">
												<p style="text-align:justify; ">
													Learning query and item representations is important for building large scale recommendation systems. In many real applications where there is a huge catalog of items to recommend, the problem of efficiently retrieving top k items given user’s query from deep corpus leads to a family of factorized modeling approaches where queries and items are jointly embedded into a low-dimensional space. In this paper, we first showcase how to apply a two-tower neural network framework, which is also known as dual encoder in the natural language community, to improve a large-scale, production app recommendation system. Furthermore, we offer a novel negative sampling approach called Mixed Negative Sampling (MNS). In particular, different from commonly used batch or unigram sampling methods, MNS uses a mixture of batch and uniformly sampled negatives to tackle the selection bias of implicit user feedback. We conduct extensive offline experiments using large-scale production dataset and show that MNS outperforms other baseline sampling methods. We also conduct online A/B testing and demonstrate that the two-tower retrieval model based on MNS significantly improves retrieval quality by encouraging more high-quality app installs.
												</p>
	                                        </section>
										</div> 
									</div>
						    		<p><br\></br\></p>
									<div>[2] Xiaolan Wang, Xin Luna Dong, <strong>Yang Li</strong> and Alexandra Meliou, "<strong>MIDAS: Finding the Right Web Sources to Fill Knowledge Gaps</strong>", <em>Proc. of the 35th IEEE International Conference on Data Engineering (<b>ICDE'19</b>)</em>, Macau SAR, China, April 2019. <a style="cursor: pointer;" onclick="toggle_visibility('icde19_wang');">[Abstract]</a> <a href="#pubs">[Paper]</a> <a href="#pubs">  [Citations]</a>
	                                    <div id="icde19_wang" style="display: none;">
	                                    	<section class="box box-style1">
												<p style="text-align:justify; ">
													Knowledge bases, massive collections of facts (RDF triples) on diverse topics, support vital modern applications. However, existing knowledge bases contain very little data compared to the wealth of information on the Web. This is because the industry standard in knowledge base creation and augmentation suffers from a serious bottleneck: they rely on domain experts to identify appropriate web sources to extract data from. Efforts to fully automate knowledge extraction have failed to improve this standard: these automated systems are able to retrieve much more data and from a broader range of sources, but they suffer from very low precision and recall. As a result, these large-scale extractions remain unexploited. In this paper, we present MIDAS, a system that harnesses the results of automated knowledge extraction pipelines to repair the bottleneck in industrial knowledge creation and augmentation processes. MIDAS automates the suggestion of good-quality web sources and describes what to extract with respect to augmenting an existing knowledge base. We make three major contributions. First, we introduce a novel concept, web source slices, to describe the contents of a web source. Second, we define a profit function to quantify the value of a web source slice with respect to augmenting an existing knowledge base. Third, we develop effective and highly-scalable algorithms to derive high-profit web source slices. We demonstrate that MIDAS produces high-profit results and outperforms the baselines significantly on both real-word and synthetic datasets. 
												</p>
	                                        </section>
										</div> 
									</div>
						    		<p><br\></br\></p>
									<div>[3] David Gold, Takeo Katsuki, <strong>Yang Li</strong>, Xifeng Yan, Michael Regulski, David Ibberson, Thomas Holstein, Robert Steele, David Jacobs, and Ralph Greenspan, "<strong>The Genome of the Jellyfish Aurelia and the Evolution of Animal Complexity</strong>", <em>Nature Ecology and Evolution</em>, 2018. <a style="cursor: pointer;" onclick="toggle_visibility('nature18_gold');">[Abstract]</a> <a href="paper/nature18_gold.pdf">[Paper]</a> <a href="#pubs">  [Citations]</a>
	                                    <div id="nature18_gold" style="display: none;">
	                                    	<section class="box box-style1">
												<p style="text-align:justify; ">
													We present the genome of the moon jellyfish Aurelia, the first genome from a cnidarian with a medusa life stage. Our analyses suggest that gene gain and loss in Aurelia is comparable to what has been found in its morphologically simpler relatives—the anthozoan corals and sea anemones. RNA-Seq analysis does not support the hypothesis that taxonomically restricted (orphan) genes play an oversized role in the development of the medusa stage. Instead, genes broadly conserved across animals and eukaryotes play comparable roles throughout the life cycle. All life stages of Aurelia are significantly enriched in the expression of genes that are hypothesized to interact in protein networks found in bilaterian animals. Collectively, our results suggest that increased life cycle complexity in Aurelia does not correlate with an increased number of genes. This leads to two possible evolutionary scenarios: either medusozoans evolved their complex medusa life stage (with concomitant shifts into new ecological niches) primarily by re-working genetic pathways already present in the last common ancestor of cnidarians, or the earliest cnidarians had a medusa life stage, which was subsequently lost in the anthozoans. While we favor the earlier hypothesis, the latter is consistent with growing evidence that many of the earliest animals were more physically complex than previously hypothesized. 
												</p>
	                                        </section>
										</div> 
									</div>
							    		<p><br\></br\></p>
										<div>[4] <strong>Yang Li</strong>, Bo Zhao, Ariel Fuxman and Fangbo Tao, "<strong>Guess Me If You Can: Acronym Disambiguation for Enterprises</strong>", <em>Proc. of the 56th Annual Meeting of the Association for Computational Linguistics (<b>ACL'18</b>)</em>, Melbourne, Australia, July 2018. <a style="cursor: pointer;" onclick="toggle_visibility('acl18_li');">[Abstract]</a> <a href="paper/acl18_li.pdf">[Paper]</a> <a href="#pubs">  [Citations]</a>
		                                    <div id="acl18_li" style="display: none;">
		                                    	<section class="box box-style1">
													<p style="text-align:justify; ">
		                                           		Acronyms are abbreviations formed from the initial components of words or phrases. In enterprises, people often use acronyms to make communications more efficient. However, acronyms could be difficult to understand for people who are not familiar with the subject matter (new employees, etc.), thereby affecting productivity. To alleviate such troubles, we study how to automatically resolve the true meanings of acronyms in a given context. Acronym disambiguation for enterprises is challenging for several reasons. First, acronyms may be highly ambiguous since an acronym used in the enterprise could have multiple internal and external meanings. Second, there are usually no comprehensive knowledge bases such as Wikipedia available in enterprises. Finally, the system should be generic to work for any enterprise. In this work we propose an end-to-end framework to tackle all these challenges. The framework takes the enterprise corpus as input and produces a high-quality acronym disambiguation system as output. Our disambiguation models are trained via distant supervised learning, without requiring any manually labeled training examples. Therefore, our proposed framework can be deployed to any enterprise to support high-quality acronym disambiguation. Experimental results on real world data justified the effectiveness of our system.
													</p>
		                                        </section>
											</div> 
										</div>
										<p><br\></br\></p>
										<div>[5] Furong Li, Luna Dong, Anno Langen and <strong>Yang Li</strong>, "<strong>Knowledge Verification for Long-tail Verticals</strong>", <em>Proc. of the 43th International Conference on Very Large Databases (<b>VLDB'17</b>)</em>, Munich, Germany, August 2017. <a style="cursor: pointer;" onclick="toggle_visibility('vldb17_li');">[Abstract]</a> <a href="paper/vldb17_li.pdf">[Paper]</a> <a href="https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8873493742801302149">  [Citations]</a>
		                                    <div id="vldb17_li" style="display: none;">
		                                    	<section class="box box-style1">
													<p style="text-align:justify; ">
		                                           		Collecting structured knowledge for real-world entities has become a critical task for many applications. A big gap between the knowledge in existing knowledge repositories and the knowledge in the real world is the knowledge on tail verticals (i.e., less popular domains). Such knowledge, though not necessarily globally popular, can be personal hobbies to many people and thus collectively impactful. This paper studies the problem of knowledge verification for tail verticals; that is, deciding the correctness of a given triple.
		Through comprehensive experimental study we answer the following questions. 1) Can we find evidence for tail knowledge from an extensive set of sources, including knowledge bases, the web, and query logs? 2) Can we judge correctness of the triples based on the collected evidence? 3) How can we further improve knowledge verification on tail verticals? Our empirical study suggests a new knowledge-verification framework, which we call Facty, that applies various kinds of evidence collection techniques followed by knowledge fusion. Facty can verify 50% of the (correct) tail knowledge with a precision of 84%, and it significantly outperforms state-of-the-art methods. Detailed error analysis on the obtained results suggests future research directions.
													</p>
		                                        </section>
											</div> 
										</div>
										<p><br\></br\></p>
									<div>[6] <strong>Yang Li</strong>, Shulong Tan, Huan Sun, Jiawei Han, Dan Roth and Xifeng Yan, "<strong>Entity Disambiguation with Linkless Knowledge Bases</strong>", <em>Proc. of the 25th International World Wide Web Conference (<b>WWW'16</b>)</em>, Montréal, Québec, Canada, April 2016. <a style="cursor: pointer;" onclick="toggle_visibility('www16_li');">[Abstract]</a> <a href="paper/www16_li.pdf">[Paper]</a> <a href="paper/www16_li_slides.pdf">[Slides]</a> <a href="https://scholar.google.com/citations?view_op=view_citation&citation_for_view=AkfRRDAAAAAJ:LPZeul_q3PIC">[Citations]</a>
	                                    <div id="www16_li" style="display: none;">
	                                    	<section class="box box-style1">
												<p style="text-align:justify; ">
	                                           	Named Entity Disambiguation is the task of disambiguating named entity 
												mentions in natural language text and link them to their corresponding 
												entries in a reference knowledge base (e.g. Wikipedia). Such disambiguation 
												can help add semantics to plain text and distinguish homonymous entities. 
												Previous research has tackled this problem by making use of two types of 
												context-aware features derived from the reference knowledge base, namely, 
												the context similarity and the semantic relatedness. Both features heavily 
												rely on the cross-document hyperlinks within the knowledge base: the 
												semantic relatedness feature is directly measured via those hyperlinks, 
												while the context similarity feature implicitly makes use of those 
												hyperlinks to expand entity candidates' descriptions and then compares 
												them against the query context. Unfortunately, cross-document hyperlinks 
												are rarely available in many closed domain knowledge bases and it is very 
												expensive to manually add such links. Therefore few algorithms can work 
												well on linkless knowledge bases. In this work, we propose the challenging 
												Named Entity Disambiguation with Linkless Knowledge Bases (LNED) problem 
												and tackle it by leveraging the useful disambiguation evidences scattered 
												across the reference knowledge base. We propose a generative model to 
												automatically mine such evidences out of noisy information. The mined 
												evidences can mimic the role of the missing links and help boost the LNED 
												performance. Experimental results show that our proposed method substantially 
												improves the disambiguation accuracy over the baseline approaches.
												</p>
	                                        </section>
										</div> 
									</div>

										<p><br\></br\></p>
									<div>[7] <strong>Yang Li</strong>, Peter Clark, "<strong>Answering Elementary Science Questions by Constructing Coherent Scenes Using Background Knowledge</strong>", <em>Proc. of the Conference on Empirical Methods in Natural Language Processing (<b>EMNLP'15</b>)</em>, Lisboa, Portugal, September 2015. <a style="cursor: pointer;" onclick="toggle_visibility('emnlp15_li');">[Abstract]</a> <a href="paper/emnlp15_li.pdf">[Paper]</a> <a href="paper/emnlp15_li_slides.pdf">[Slides]</a> <a href="https://vimeo.com/169430643#t=NaNs">[Video]</a> <a href="https://scholar.google.com/citations?view_op=view_citation&citation_for_view=AkfRRDAAAAAJ:u9iWguZQMMsC">[Citations]</a> 
                                    	<div id="emnlp15_li" style="display: none;">
                                    		<section class="box box-style1">
												<p style="text-align:justify; ">
												Much of what we understand from text is not explicitly stated. Rather,
												the reader uses his/her knowledge to fill in gaps and create a
												coherent, mental picture or "scene" depicting what text 
												appears to convey. The scene constitutes an understanding of
												the text, and can be used to answer questions that go beyond the text.
												Our goal is to answer elementary science questions, where this
												requirement is pervasive; A question will often give a partial
												description of a scene and ask the student about implicit information.
												We show that by using a simple "knowledge graph" representation
												of the question, we can leverage several large-scale linguistic
												resources to provide missing background knowledge, somewhat alleviating 
												the knowledge bottleneck in previous approaches. 								
												The coherence of the best resulting scene, 
												built from a question/answer-candidate pair, reflects the confidence 
												that the answer candidate is correct, and thus can
												be used to answer multiple choice questions. Our experiments show that 
												this approach outperforms competitive algorithms 
												on several datasets tested. The significance of this work is thus to show 
												that a simple "knowledge graph" representation allows a version of 
												"interpretation as scene construction" to be made viable.
												</p>
                                        	</section>
										</div> 
									</div>
									
									<p><br\></br\></p> 
									
									<div>[8] Fangbo Tao, Bo Zhao, Ariel Fuxman, <strong>Yang Li</strong> and Jiawei Han, "<strong>Leveraging Pattern Semantics for Extracting Entities in Enterprises"</strong>", <em>Proc. of the 24th International World Wide Web Conference (<b>WWW'15</b>)</em>, Florence, Italy, May 2015. <a style="cursor: pointer;" onclick="toggle_visibility('www15_tao');">[Abstract]</a> <a href="paper/www15_tao.pdf">[Paper]</a> <a href="https://scholar.google.com/citations?view_op=view_citation&citation_for_view=AkfRRDAAAAAJ:OU6Ihb5iCvQC">[Citations]</a>
                                    	<div id="www15_tao" style="display: none;">
                                    		<section class="box box-style1">
												<p style="text-align:justify; ">
                                           			Entity Extraction is a process of identifying meaningful 
													entities from text documents. In enterprises, extracting 
													entities improves enterprise efficiency by facilitating 
													numerous applications, including search, recommendation, 
													etc. However, the problem is particularly challenging on 
													enterprise domains due to several reasons. First, the lack 
													of redundancy of enterprise entities makes previous web-based 
													systems like NELL and OpenIE not effective, since using only 
													high-precision/low-recall patterns like those systems would 
													miss the majority of sparse enterprise entities, while using 
													more low-precision patterns in sparse setting also introduces 
													noise drastically. Second, semantic drift is common in enterprises 
													("Blue" refers to "Windows Blue"), such that public signals from 
													the web cannot be directly applied on entities. Moreover, many 
													internal entities never appear on the web.
													Sparse internal signals are the only source for discovering
													them. To address these challenges, we propose an end-to-end 
													framework for extracting entities in enterprises, taking
													the input of enterprise corpus and limited seeds to generate
													a high-quality entity collection as output. We introduce the
													novel concept of Semantic Pattern Graph to leverage public 
													signals to understand the underlying semantics of lexical
													patterns, reinforce pattern evaluation using mined semantics
													, and yield more accurate and complete entities. Experiments
													on Microsoft enterprise data show the effectiveness of
													our approach.
												</p>
                                        	</section>
										</div> 
									</div>
									
									<p><br\></br\></p>
									
									<div>[9] Huan Sun, Mudhakar Srivatsa, Shulong Tan, <strong>Yang Li</strong>, Lance Kaplan, Shu Tao and Xifeng Yan, "<strong>Analyzing Expert Behaviors in Collaborative Networks</strong>", <em>Proc. of the 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<b>KDD'14</b>)</em>, New York, NY, USA, August 2014. <a style="cursor: pointer;" onclick="toggle_visibility('kdd14_sun');">[Abstract]</a> <a href="paper/kdd14_sun.pdf">[Paper]</a> <a href="paper/kdd14_sun_slides.pdf">[Slides]</a> <a href="paper/kdd14_sun_poster.pdf">[Poster]</a> <a href="https://scholar.google.com/citations?view_op=view_citation&citation_for_view=AkfRRDAAAAAJ:uWQEDVKXjbEC">[Citations]</a>
                                    	<div id="kdd14_sun" style="display: none;">
                                    		<section class="box box-style1">
												<p style="text-align:justify; ">
                                           		Collaborative networks are composed of experts who cooperate
                                           		with each other to complete specific tasks, such as
                                           		resolving problems reported by customers. A task is posted
                                           		and subsequently routed in the network from an expert to
                                           		another until being resolved. When an expert cannot solve
                                           		a task, his routing decision (i.e., where to transfer a task) is
                                           		critical since it can significantly affect the completion time
                                           		of a task. In this work, we attempt to deduce the cognitive
                                           		process of task routing, and model the decision making of
                                           		experts as a generative process where a routing decision is
                                           		made based on mixed routing patterns.
                                           		In particular, we observe an interesting phenomenon that
                                           		an expert tends to transfer a task to someone whose knowledge
                                           		is neither too similar to nor too different from his own.
                                           		Based on this observation, an expertise difference based routing
                                           		pattern is developed. We formalize multiple routing
                                           		patterns by taking into account both rational and random
                                           		analysis of tasks, and present a generative model to combine
                                           		them. For a held-out set of tasks, our model not only
                                           		explains their real routing sequences very well, but also accurately
                                           		predicts their completion time. Under three different
                                           		quality measures, our method significantly outperforms all
                                           		the alternatives with more than 75% accuracy gain. In
                                           		practice, with the help of our model, hypotheses on how to
                                           		improve a collaborative network can be tested quickly and
                                           		reliably, thereby significantly easing performance improvement
                                           		of collaborative networks.
												</p>
                                        	</section>
										</div> 
									</div>
									
									<p><br\></br\></p>
									
									<div>[10] <strong>Yang Li</strong>, Chi Wang, Fangqiu Han, Jiawei Han, Dan Roth and Xifeng Yan, "<strong>Mining Evidences for Named Entity Disambiguation</strong>", <em>Proc. of the 19th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<b>KDD'13</b>)</em>, Chicago, IL, USA, August 2013. <a style="cursor: pointer;" onclick="toggle_visibility('kdd13_li');">[Abstract]</a> <a href="paper/kdd13_li.pdf">[Paper]</a> <a href="paper/kdd13_li_poster.pdf">[Poster]</a> <a href="https://scholar.google.com/citations?view_op=view_citation&citation_for_view=AkfRRDAAAAAJ:u5HHmVD_uO8C">[Citations]</a>
                                    	<div id="kdd13_li" style="display: none;">
                                    		<section class="box box-style1">
												<p style="text-align:justify; ">
                                           		Named entity disambiguation is the task of disambiguating
                                           		named entity mentions in natural language text and link
                                           		them to their corresponding entries in a knowledge base
                                           		such as Wikipedia. Such disambiguation can help enhance
                                           		readability and add semantics to plain text. It is also a
                                           		central step in constructing high-quality information network
                                           		or knowledge graph from unstructured text. Previous
                                           		research has tackled this problem by making use of various
                                           		textual and structural features from a knowledge base.
                                           		Most of the proposed algorithms assume that a knowledge
                                           		base can provide enough explicit and useful information to
                                           		help disambiguate a mention to the right entity. However,
                                           		the existing knowledge bases are rarely complete (likely will
                                           		never be), thus leading to poor performance on short queries
                                           		with not well-known contexts. In such cases, we need to collect
                                           		additional evidences scattered in internal and external
                                           		corpus to augment the knowledge bases and enhance their
                                           		disambiguation power. In this work, we propose a generative
                                           		model and an incremental algorithm to automatically
                                           		mine useful evidences across documents. With a specific
                                           		modeling of "background topic" and "unknown entities", our
                                           		model is able to harvest useful evidences out of noisy information.
                                           		Experimental results show that our proposed
                                           		method outperforms the state-of-the-art approaches significantly:
                                           		boosting the disambiguation accuracy from 43%
                                           		(baseline) to 86% on short queries derived from tweets.
												</p>
                                        	</section>
										</div>
									</div>
									
									<p><br\></br\></p>
									
									<div>[11] <strong>Yang Li</strong>, Pegah Kamousi, Fangqiu Han, Shengqi Yang, Xifeng Yan and Subhash Suri, "<strong>Memory Efficient Minimum Substring Partitioning</strong>", <em>Proc. of the 39th International Conference on Very Large Databases (<b>VLDB'13</b>)</em>, Riva del Garda, Trento, Italy, August 2013. <a style="cursor: pointer;" onclick="toggle_visibility('vldb13_li');">[Abstract]</a> <a href="paper/vldb13_li.pdf">[Paper]</a> <a href="paper/vldb13_li_slides.pdf">[Slides]</a> <a href="http://ucsdnews.ucsd.edu/pressrelease/scientists_help_tame_tidal_wave_of_genomic_data_using_sdscs_emtrestles_em">[Press]</a> <a href="https://scholar.google.com/citations?view_op=view_citation&citation_for_view=AkfRRDAAAAAJ:u-x6o8ySG0sC">[Citations]</a>
                                    	<div id="vldb13_li" style="display: none;">
                                    		<section class="box box-style1">
												<p style="text-align:justify; ">
                                           		Massively parallel DNA sequencing technologies are revolutionizing
                                           		genomics research. Billions of short reads generated
                                           		at low costs can be assembled for reconstructing the
                                           		whole genomes. Unfortunately, the large memory footprint
                                           		of the existing de novo assembly algorithms makes it challenging
                                           		to get the assembly done for higher eukaryotes like
                                           		mammals. In this work, we investigate the memory issue of
                                           		constructing de Bruijn graph, a core task in leading assembly
                                           		algorithms, which often consumes several hundreds of gigabytes
                                           		memory for large genomes. We propose a disk-based
                                           		partition method, called Minimum Substring Partitioning
                                           		(MSP), to complete the task using less than 10 gigabytes
                                           		memory, without runtime slowdown. MSP breaks the short
                                           		reads into multiple small disjoint partitions so that each
                                           		partition can be loaded into memory, processed individually
                                           		and later merged with others to form a de Bruijn graph.
                                           		By leveraging the overlaps among the k-mers (substring of
                                           		length k), MSP achieves astonishing compression ratio: The
                                           		total size of partitions is reduced from Θ(kn) to Θ(n), where
                                           		n is the size of the short read database, and k is the length
                                           		of a k-mer. Experimental results show that our method can
                                           		build de Bruijn graphs using a commodity computer for any
                                           		large-volume sequence dataset.
												</p>
                                        	</section>
										</div>
									</div>
									
									<p><br\></br\></p>
									
									<div>[12] Shulong Tan, <strong>Yang Li</strong>, Huan Sun, Ziyu Guan, Xifeng Yan, Jiajun Bu, Chun Chen and Xiaofei He, "<strong>Interpreting Public Sentiment Variations on Twitter</strong>", <em>Transactions on Knowledge and Data Engineering (<b>TKDE'13</b>)</em>, August 2013. <a style="cursor: pointer;" onclick="toggle_visibility('tkde13_tan');">[Abstract]</a> <a href="paper/tkde13_tan.pdf">[Paper]</a> <a href="https://scholar.google.com/citations?view_op=view_citation&citation_for_view=AkfRRDAAAAAJ:d1gkVwhDpl0C">[Citations]</a> 
                                    	<div id="tkde13_tan" style="display: none;">
                                    		<section class="box box-style1">
												<p style="text-align:justify; ">
                                           		Millions of users share their opinions on Twitter, making it a valuable platform for tracking and analyzing public
                                           		sentiment. Such tracking and analysis can provide critical information for decision making in various domains. Therefore it has
                                           		attracted attention in both academia and industry. Previous research mainly focused on modeling and tracking public sentiment.
                                           		In this work, we move one step further to interpret sentiment variations. We observed that emerging topics (named foreground
                                           		topics) within the sentiment variation periods are highly related to the genuine reasons behind the variations. Based on this
                                           		observation, we propose a Latent Dirichlet Allocation (LDA) based model, Foreground and Background LDA (FB-LDA), to distill
                                           		foreground topics and filter out longstanding background topics. These foreground topics can give potential interpretations of
                                           		the sentiment variations. To further enhance the readability of the mined reasons, we select the most representative tweets for
                                           		foreground topics and develop another generative model called Reason Candidate and Background LDA (RCB-LDA) to rank
                                           		them with respect to their "popularity" within the variation period. Experimental results show that our methods can effectively find
                                           		foreground topics and rank reason candidates. The proposed models can also be applied to other tasks such as finding topic
                                           		differences between two sets of documents.
												</p>
                                        	</section>
										</div>
									</div>
									
									<p><br\></br\></p>
									
									<div>[13] <strong>Yang Li</strong> and Xifeng Yan, "<strong>MSPKmerCounter: A Fast and Memory Efficient Approach for K-mer Counting</strong>", <em>arXiv.org preprint</em>. <a style="cursor: pointer;" onclick="toggle_visibility('kc');">[Abstract]</a> <a href="paper/bio14_li.pdf">[Paper]</a> <a href="MSPKmerCounter/index.html">[Software]</a> <a href="https://scholar.google.com/citations?view_op=view_citation&citation_for_view=AkfRRDAAAAAJ:nb7KW1ujOQ8C">[Citations]</a>
                                    	<div id="kc" style="display: none;">
                                    		<section class="box box-style1">
												<p style="text-align:justify; ">
                                           		A major challenge in next-generation genome sequencing (NGS) is to assemble massive overlapping short reads that are
                                           		randomly sampled from DNA fragments. To complete assembling,
                                           		one needs to finish a fundamental task in many leading assembly
                                           		algorithms: counting the number of occurrences of k-mers (length-k 
                                           		substrings in sequences). The counting results are critical for
                                           		many components in assembly (e.g. variants detection and read
                                           		error correction). For large genomes, the k-mer counting task can
                                           		easily consume a huge amount of memory, making it impossible for
                                           		large-scale parallel assembly on commodity servers.
                                           		In this paper, we develop MSPKmerCounter, a disk-based
                                           		approach, to efficiently perform k-mer counting for large genomes
                                           		using a small amount of memory. Our approach is based on a novel
                                           		technique called Minimum Substring Partitioning (MSP). MSP breaks
                                           		short reads into multiple disjoint partitions such that each partition
                                           		can be loaded into memory and processed individually. By leveraging 
                                           		the overlaps among the k-mers derived from the same short
                                           		read, MSP can achieve astonishing compression ratio so that the
                                           		I/O cost can be significantly reduced. For the task of k-mer counting,
                                           		MSPKmerCounter offers a very fast and memory-efficient solution.
                                           		Experiment results on large real-life short reads data sets demon-
                                           		strate that MSPKmerCounter can achieve better overall performance
                                           		than state-of-the-art k-mer counting approaches.
												</p>
                                        	</section>
										</div> 
									</div>
								</li>
							</ul>
						</div>
					</div>


					<footer>
						<a href="http://scholar.google.com/citations?user=AkfRRDAAAAAJ&hl=en" class="button big scrolly">Google Scholar</a>
					</footer>
				</article>
			</div>


		<!-- Work -->
			<div class="wrapper style3">
				<article id="work">
					<header>
						<h2>Previous Work Experience</h2>
					</header>
					<div class="container">
						<div class="row">
							<div class="4u">
								<article class="box style2">
									<a href="http://allenai.org/" class="image featured"><img src="images/ai2.jpg" alt="" /></a>
									<h3><a href="http://allenai.org/">Allen Institute for AI</a></h3>
									<h4>Research Intern</h4>
                                    <span>Jan. 2015 - Apr. 2015</span>
                                    <p>Seattle, WA</p>
								</article>
							</div>
							<div class="4u">
								<article class="box style2">
									<a href="http://research.microsoft.com/en-us/labs/siliconvalley/" class="image featured"><img src="images/msr.png" alt="" /></a>
									<h3><a href="http://research.microsoft.com/en-us/labs/siliconvalley/">Microsoft Research</a></h3>
									<h4>Research Intern</h4>
                                    <span>Jun. 2014 - Sep. 2014</span>
                                    <p>Mountain View, CA</p>
								</article>
							</div>
							<div class="4u">
								<article class="box style2">
									<a href="https://www.apple.com/" class="image featured"><img src="images/apple.jpg" alt="" /></a>
									<h3><a href="https://www.apple.com/">Apple Inc.</a></h3>
									<h4>Research Intern</h4>
                                    <span>Jun. 2013 - Sep. 2013</span>
                                    <p>Cupertino, CA</p>
								</article>
							</div>
							
							<!--
							<div class="4u">
								<article class="box style2">
									<a href="http://www.microsoft.com/china/ard/en/groups.mspx" class="image featured"><img src="images/microsoft.jpg" alt="" /></a>
									<h3><a href="http://www.microsoft.com/china/ard/en/groups.mspx">Microsoft China</a></h3>
									<h4>Research Intern</h4>
                                    <span>Dec. 2009 - Apr. 2010</span>
                                    <p>Beijing, China</p>
								</article>
							</div>
							-->
							
						</div>
					</div>
					<!--<footer>
						<p>Lorem ipsum dolor sit sapien vestibulum ipsum primis?</p>
						<a href="#contact" class="button big scrolly">Get in touch with me</a>
					</footer>-->
				</article>
			</div>

		<!-- Contact -->
			<div class="wrapper style4">
				<article id="contact" class="container small">
					<header>
						<h2>Contact Me</h2>
					</header>
					<div class="row">
							<div class="4u">
								<article class="box style2">
									<a href="mailto:zheda2006liyang@gmail.com" class="image image-full"><img src="images/email.png" alt="" /></a>
                                	<img src="images/emailaddr.png" width="172" height="23" alt=""> 
                                </article>
							</div>
							<div class="4u">
						  		<article class="box style2">
									<a href="#contact" class="image image-full"><img src="images/phone.png" alt="" /></a>
                                    <img src="images/phonenum.jpg" width="120" height="20" alt=""> 
								</article>
							</div>
							<div class="4u">
						  		<article class="box style2">
									<a href="#contact" class="image image-full"><img src="images/lab.png" alt="" /></a>
									<img src="images/addr.png" width="90" height="18" alt=""> 
								</article>
							</div>
				  </div>
					<div>

						<!--<div class="row">
							<div class="12u">
								<form method="post" action="#">
									<div>
										<div class="row">
											<div class="6u">
												<input type="text" name="name" id="name" placeholder="Name" />
											</div>
											<div class="6u">
												<input type="text" name="email" id="email" placeholder="Email" />
											</div>
										</div>
										<div class="row">
											<div class="12u">
												<input type="text" name="subject" id="subject" placeholder="Subject" />
											</div>
										</div>
										<div class="row">
											<div class="12u">
												<textarea name="message" id="message" placeholder="Message"></textarea>
											</div>
										</div>
										<div class="row double">
											<div class="12u">
												<ul class="actions">
													<li><input type="submit" value="Send Message" /></li>
													<li><input type="reset" value="Clear Form" class="alt" /></li>
												</ul>
											</div>
										</div>
									</div>
								</form>
							</div>
						</div>-->
						<div class="row">
							<div class="12u">
								<hr />
								<h3>Find me on ...</h3>
								<ul class="social">
									<li><a href="http://www.facebook.com/yangli.cs" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
									<li><a href="https://www.linkedin.com/in/yangli1989" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>	
									<li><a href="https://plus.google.com/112065435031385428341/" class="icon fa-google-plus"><span class="label">Google+</span></a></li>
									<li><a href="http://www.quora.com/Yang-Li" class="icon fa-quora"><span class="label">Quora</span></a></li>
									<!--
									<li><a href="" title="primerzju" class="icon fa-wechat"><span class="label">Wechat</span></a></li>
									-->	
									<li><a href="javascript:void(0);" onclick="javascript:openwindow('wechat.jpg','Scan to add me on Wechat',380,506);" class="icon fa-wechat"><span class="label">Wechat</span></a></li>

									<!--
									<li><a href="http://www.quora.com/Yang-Li" class="icon fa-fw"><img src="images/quora.png" width="48" height="48" alt="" /><span class="label">Quora</span></a></li>
									<li><a href="#" class="icon fa-rss"><span>RSS</span></a></li>
									<li><a href="#" class="icon fa-instagram"><span>Instagram</span></a></li>
									<li><a href="#" class="icon fa-foursquare"><span>Foursquare</span></a></li>
									<li><a href="#" class="icon fa-skype"><span>Skype</span></a></li>
									<li><a href="#" class="icon fa-soundcloud"><span>Soundcloud</span></a></li>
									<li><a href="#" class="icon fa-youtube"><span>YouTube</span></a></li>
									<li><a href="#" class="icon fa-blogger"><span>Blogger</span></a></li>
									<li><a href="#" class="icon fa-flickr"><span>Flickr</span></a></li>
									<li><a href="#" class="icon fa-vimeo"><span>Vimeo</span></a></li>
									-->
								</ul>
								<hr />
							</div>
						</div>
					</div>
					<footer>
                    <img src="http://hitwebcounter.com/counter/counter.php?page=7060347&style=0025&nbdigits=4&type=page&initCount=8688" title="" Alt=""   border="0" >
					<br/>
					<h8>Visitors Since January 1, 2011</h8>
                    <br/>
                    <br/>
						<ul id="copyright">
							<li>&copy; 2021 <a href="index.html">Yang Li</a></li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</footer>
				</article>
			</div>

	</body>
</html>
